{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training and Testing\n",
    "Only the video data in its first 15 seconds of one file indexed 3396 is used to illustrate the model training and testing process with time efficiency.\n",
    "### Pre-setting\n",
    "- Import relevant modules\n",
    "- Define preconfigured global variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from torch.utils.data.dataset import random_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pre_processing.utils import build_bandpass_filter\n",
    "from models.cnn3d import CNN\n",
    "\n",
    "torch.manual_seed(1) \n",
    "FPS = 61\n",
    "WINDOW_LEN = FPS * 10 # frame number for 10-second video clips\n",
    "time_len = 15 * FPS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load and Pre-process Samples of Dataset\n",
    "- Load the three pre-processed HCI data files:  \n",
    "    seq_dir: directory of multiple json files, each json file contains a sequence of detected bounding box of one video  \n",
    "    ts_file: path of a file, the file contains the groundtruth timestamps of BVP peaks for videos in HCI database  \n",
    "    instan_hr_file: path of a file, the file contains the computed groundtruth of instantaneous heart rate for videos in HCI database  \n",
    "- Pre-process the data of bounding-box sequences:   \n",
    "resize -> bandpath filter -> syncronization -> groundtruth computation -> apply sliding window strategy to construct samples with the same time length\n",
    "- Obtain samples: [(ROI sequence in RGB channels, mean value of HR groundtruth), ...]  \n",
    "    the shape of ROI sequence in RGB channels = (n=610, c=3, w=36, h=36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All Files: dict_keys(['3396'])\n",
      "5\n"
     ]
    }
   ],
   "source": [
    "def preprocess_HCI_dataset_for_3dcnn_model(seq_dir, ts_file, instant_hr_file):\n",
    "    with open(ts_file, 'r') as file:\n",
    "        timestamps = json.load(file)\n",
    "    with open(instant_hr_file, 'r') as file:\n",
    "        instant_hr = json.load(file)\n",
    "\n",
    "    sequences = {}\n",
    "    bd_files = os.listdir(seq_dir)\n",
    "    if '.DS_Store' in bd_files:\n",
    "        bd_files.remove('.DS_Store')\n",
    "    for bd_file in bd_files:\n",
    "        with open(seq_dir + bd_file, 'r') as file:\n",
    "            sequences[bd_file[:-5]] = json.load(file)\n",
    "\n",
    "    print(\"All Files:\", sequences.keys())\n",
    "    all_data = []\n",
    "    for file_idx in sequences.keys():\n",
    "        # Resize each bounding box into size (36, 36) using average pooling\n",
    "        # Note: only 1220 frames in the first 20 seconds of video are used for illustration\n",
    "        sequence = np.array(sequences[file_idx][file_idx][:time_len])\n",
    "        sequence = np.transpose(sequence, (0, 3, 1, 2))\n",
    "        avg_pool = nn.AdaptiveAvgPool2d((36, 36))\n",
    "        sequence = avg_pool(torch.from_numpy(sequence).float())\n",
    "\n",
    "        # Apply bandpath filter for each (pixel, channel) pair sequence\n",
    "        from scipy.signal import filtfilt\n",
    "        order = 128\n",
    "        b = build_bandpass_filter(FPS, order, False)\n",
    "\n",
    "        _, _, w, h = sequence.size()\n",
    "        for i in range(w):\n",
    "            for j in range(h):\n",
    "                for c in range(3):\n",
    "                    sequence[:, c, i, j] = torch.from_numpy(filtfilt(b, np.array([1]), sequence[:, c, i, j], axis=0).copy())\n",
    "\n",
    "        # Make the input seq and target seq to have the same length\n",
    "        timestamps = timestamps[file_idx]\n",
    "        instan_hr = instant_hr[file_idx]\n",
    "        assert len(timestamps) == len(instan_hr)\n",
    "        total_length = int(min(len(sequence), timestamps[-1]))\n",
    "        sequence = sequence[: total_length]\n",
    "        timestamps = [i for i in timestamps if i <= total_length]\n",
    "        instan_hr = instan_hr[: len(timestamps)]\n",
    "\n",
    "        # Compute the mean hr seq for every 10 seconds signals from the peak timestamps as groundtruth\n",
    "        target = []\n",
    "        for start_point in range(0, total_length - WINDOW_LEN, FPS):\n",
    "            time_window = [i for i in timestamps if i >= start_point and i < start_point+WINDOW_LEN]\n",
    "            l_idx = timestamps.index(time_window[0])\n",
    "            r_idx = timestamps.index(time_window[-1])\n",
    "            target.append(np.mean(np.array(instan_hr[l_idx: r_idx+1])))\n",
    "\n",
    "        # apply the sliding window strategy to construct the dataset\n",
    "        sequence = sequence.tolist()\n",
    "        seq_windows = [[sequence[i: i + WINDOW_LEN], target[int(i/FPS)]] for i in range(0, total_length - WINDOW_LEN, FPS)]\n",
    "        all_data.extend(seq_windows)\n",
    "    return all_data\n",
    "\n",
    "seq_dir = './dataset/roi_sequence/'\n",
    "ts_file = './dataset/peak_timestamps_groundtruth_hci_tagging.json'\n",
    "instant_hr_file = './dataset/instan_hr_groundtruth_hci_tagging.json'\n",
    "all_data = preprocess_HCI_dataset_for_3dcnn_model(seq_dir, ts_file, instant_hr_file)\n",
    "print(len(all_data))\n",
    "# all_data = all_data[:len(all_data)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the Training and Testing Dataset\n",
    "- Construct two types of model input:   \n",
    "    **Frame input (x_appearance)**: the original content of the resized ROI sequence, which is used in the attention mechanism.  \n",
    "    **difference input (x_motion)**: the time-domain discrete derivative of the resized ROI sequence, which is the mainsource of pulse information in the 3D-CNN network.  \n",
    "- Split the whole dataset into two parts: 60% for training, 40% for testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_appearance = np.array([x[0] for x in all_data])\n",
    "x_motion = []\n",
    "for window in x_appearance:\n",
    "    t = window[1] - window[0]\n",
    "    diff = [window[i] - window[i-1] for i in range(1, len(window))]\n",
    "    x_motion.append(diff)\n",
    "x_appearance = np.transpose(x_appearance[:, :-1, :, :, :], (0, 2, 1, 3, 4))\n",
    "x_motion = np.transpose(np.array(x_motion), (0, 2, 1, 3, 4))\n",
    "# print(x_appearance.shape, x_motion.shape)\n",
    "x_tensor = torch.from_numpy(np.stack((x_motion, x_appearance), axis=1)).float()\n",
    "y_tensor = torch.from_numpy(np.array([[x[1]] for x in all_data])).float()\n",
    "# print(x_tensor.size(), y_tensor.size())\n",
    "dataset = TensorDataset(x_tensor, y_tensor)\n",
    "\n",
    "config = {\n",
    "\"n_epoch\": 2,\n",
    "\"batch_size\": 32\n",
    "}\n",
    "train_test_ratio = 0.6\n",
    "train_num = int(train_test_ratio * (len(dataset)))\n",
    "train_dataset, test_dataset = random_split(dataset, [train_num, len(dataset)-train_num])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "- Split the training dataset into two parts: 80% for training, 20% for validation\n",
    "- Define the 3D-CNN model, use the MSE loss function and Adam optimizer for training\n",
    "- In each epoch, train and validate the data in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 Training loss: 3875.448486328125 Validation loss: 3847.62744140625\n",
      "epoch: 1 Training loss: 3842.102783203125 Validation loss: 3810.165283203125\n"
     ]
    }
   ],
   "source": [
    "def model_train(config, train_dataset, checkpoint_dir=None):\n",
    "    val_abs = int(len(train_dataset) * 0.8)\n",
    "    train_subset, val_subset = random_split(train_dataset, [val_abs, len(train_dataset) - val_abs])\n",
    "\n",
    "    train_loader = DataLoader(dataset=train_subset, batch_size=int(config[\"batch_size\"]), shuffle=True)\n",
    "    val_loader = DataLoader(dataset=val_subset, batch_size=int(config[\"batch_size\"]), shuffle=True)\n",
    "\n",
    "    '''Define the CNN model'''\n",
    "    model = CNN()\n",
    "    # print(model.state_dict())\n",
    "    loss_function = nn.MSELoss() #(reduction='mean')\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=3 * pow(10, -3)) \n",
    "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min')\n",
    "\n",
    "    '''Model training'''\n",
    "    model.train()\n",
    "    for epoch in range(config[\"n_epoch\"]):\n",
    "        running_loss = []\n",
    "        for i, data in enumerate(train_loader, 0):\n",
    "            x_batch, y_batch = data\n",
    "            # print(x_batch.size(), y_batch.size())\n",
    "\n",
    "            predictions = model(x_batch)\n",
    "            # print(predictions.size(), y_batch.size())\n",
    "            loss = loss_function(predictions, y_batch)\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss.append(loss.item())\n",
    "\n",
    "        val_loss = []\n",
    "        mean_error = 0\n",
    "        model.eval()\n",
    "        with torch.no_grad():\n",
    "            predictions_list = []\n",
    "            targets_list = []\n",
    "            for i, data in enumerate(val_loader, 0):\n",
    "                x_batch, y_batch = data\n",
    "                predictions = model(x_batch)\n",
    "                # print(predictions.size(), y_batch.size())\n",
    "                loss = loss_function(predictions, y_batch)\n",
    "                predictions = predictions.numpy().reshape(-1)\n",
    "                y_batch = y_batch.numpy().reshape(-1)\n",
    "                predictions_list.extend(predictions.tolist())\n",
    "                targets_list.extend(y_batch.tolist())\n",
    "                mean_error += np.mean(abs(predictions-y_batch))\n",
    "                val_loss.append(loss.item())\n",
    "        scheduler.step(sum(val_loss))\n",
    "\n",
    "        print('epoch: {0} Training loss: {1} Validation loss: {2}'.format(epoch, np.mean(np.array(running_loss)), np.mean(np.array(val_loss))))\n",
    "    torch.save((model.state_dict(), optimizer.state_dict()), './models/best_model.pt')\n",
    "    return model\n",
    "\n",
    "best_trained_model = model_train(config=config, train_dataset=train_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Testing\n",
    "- Evaluate the trained model on the testing dataset by mean error, RMSE and correlation coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49523743987083435, 0.4952322542667389]\n",
      "[62.1099967956543, 62.288047790527344]\n",
      "Best trail test set err: 61.70378875732422 rmse: 61.70378875732422 correlation coefficient: -1.0 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "n_plot = 1 # the No. of the drawed result plot\n",
    "\n",
    "def test_accuracy(model, test_dataset):\n",
    "    test_batch_size = 1\n",
    "    test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=test_batch_size, shuffle=False)\n",
    "    model.eval()\n",
    "    # scaler = StandardScaler()\n",
    "    with torch.no_grad():\n",
    "        err_list = []\n",
    "        rmse_list = []\n",
    "        cor_list = []\n",
    "        predictions_list = []\n",
    "        targets_list = []\n",
    "        for sequence, targets in test_loader:\n",
    "#             print(sequence.size())\n",
    "            predictions = model(sequence)\n",
    "\n",
    "            # The results are scalers while the code is for vector output\n",
    "            predictions = predictions.numpy().reshape(-1)\n",
    "            targets = targets.numpy().reshape(-1)\n",
    "            errs = abs(predictions - targets)\n",
    "            err = np.mean(errs)\n",
    "            rmse = np.sqrt(np.mean(errs**2))\n",
    "            # print(predictions, targets)\n",
    "\n",
    "            predictions_list.extend(predictions.tolist())\n",
    "            targets_list.extend(targets.tolist())\n",
    "            err_list.append(err)\n",
    "            rmse_list.append(rmse)\n",
    "#         draw_picture(predictions_list, targets_list)\n",
    "        print(predictions_list)\n",
    "        print(targets_list)\n",
    "        cor = np.corrcoef(np.array(predictions_list), np.array(targets_list))[0][1]\n",
    "        cor_list.append(cor)\n",
    "        print(\"Best trail test set err: {0} rmse: {1} correlation coefficient: {2} \\n\".format(np.mean(np.array(err_list)), np.mean(np.array(rmse_list)), np.mean(np.array(cor_list))))\n",
    "        \n",
    "test_accuracy(best_trained_model, test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
